{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Flatten\n",
    "# import scipy.ndimage as ndimage\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU available:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": "'2.1.0'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "print(\"Number of GPU available: \",len(tf.config.experimental.list_physical_devices(\"GPU\")))\n",
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  for n in range(25):\n",
    "      ax = plt.subplot(5,5,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      plt.title(CLASS_NAMES[label_batch[n]])\n",
    "      plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return tf.reshape(tf.where(parts[-2] == CLASS_NAMES),[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Cast and normalize the image to dtype float32 in [0,1]\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# below functions rotate image using non-tensorflow ndimage py_function\n",
    "# def random_rotate_image(image):\n",
    "#   image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n",
    "#   return image\n",
    "#\n",
    "# def tf_random_rotate_image(image, label):\n",
    "#   im_shape = image.shape\n",
    "#   [image,] = tf.py_function(random_rotate_image, [image], [tf.float32])\n",
    "#   image.set_shape(im_shape)\n",
    "#   return image, label\n",
    "#\n",
    "# rot_ds = train_ds.map(tf_random_rotate_image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Natively, you can only use tf.image to augment.\n",
    "# You can use tf.py_function to use outside functions such as scipy.ndimage\n",
    "def augment(image):\n",
    "  # image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  # image = tf.image.resize_with_crop_or_pad(image, IMG_WIDTH+6, IMG_HEIGHT+6) # Add 6 pixels of padding\n",
    "  # image = tf.image.random_crop(image, size=[IMG_WIDTH, IMG_HEIGHT, 3]) # Random crop back to 28x28\n",
    "  # image = tf.image.random_contrast(image, lower, upper, seed=None)\n",
    "  image = tf.image.random_brightness(image, max_delta=0.1) # Random brightness\n",
    "  image = tf.image.random_flip_left_right(image,seed=5)\n",
    "  image = tf.image.random_flip_up_down(image, seed=5)\n",
    "  image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "  # image = tf.image.random_jpeg_quality(image, min_jpeg_quality, max_jpeg_quality, seed=5)\n",
    "  # image = tf.image.random_saturation(image, lower, upper, seed=5)\n",
    "  return image\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir=r'C:\\Users\\kuki\\Desktop\\Skin\\TensorData\\train'\n",
    "# object-oriented pure path\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "# list all jpeg images\n",
    "train_image_count = len(list(data_dir.glob('*\\*.jpg')))\n",
    "train_image_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([], dtype=float64)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\" and item.name != \".DS_store\"])\n",
    "CLASS_NAMES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: C:\\\\Users\\\\kuki\\\\Desktop\\\\Skin\\\\TensorData\\\\train/*/*'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-18-31be241b748e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mlist_ds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlist_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;34m'*/*'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mlist_ds\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Tensorflow-Tutorial-Kyu/venv/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001B[0m in \u001B[0;36mlist_files\u001B[0;34m(file_pattern, shuffle, seed)\u001B[0m\n\u001B[1;32m   1066\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1067\u001B[0m       assert_not_empty = control_flow_ops.Assert(\n\u001B[0;32m-> 1068\u001B[0;31m           condition, [message], summarize=1, name=\"assert_not_empty\")\n\u001B[0m\u001B[1;32m   1069\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol_dependencies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0massert_not_empty\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1070\u001B[0m         \u001B[0mmatching_files\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0midentity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmatching_files\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Tensorflow-Tutorial-Kyu/venv/lib/python3.7/site-packages/tensorflow_core/python/util/tf_should_use.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    233\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mdecorated\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 235\u001B[0;31m       return _add_should_use_warning(fn(*args, **kwargs),\n\u001B[0m\u001B[1;32m    236\u001B[0m                                      \u001B[0mwarn_in_eager\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mwarn_in_eager\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m                                      error_in_function=error_in_function)\n",
      "\u001B[0;32m~/PycharmProjects/Tensorflow-Tutorial-Kyu/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mAssert\u001B[0;34m(condition, data, summarize, name)\u001B[0m\n\u001B[1;32m    154\u001B[0m           \u001B[0mop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m           \u001B[0mmessage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Expected '%s' to be true. Summarized data: %s\"\u001B[0m \u001B[0;34m%\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 156\u001B[0;31m           (condition, \"\\n\".join(data_str)))\n\u001B[0m\u001B[1;32m    157\u001B[0m     \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: C:\\\\Users\\\\kuki\\\\Desktop\\\\Skin\\\\TensorData\\\\train/*/*'"
     ]
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "list_ds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for f in list_ds.take(5):\n",
    "  print(f.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 100\n",
    "IMG_WIDTH = 100\n",
    "BATCH_SIZE = 64\n",
    "epochs = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for image, label in labeled_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", CLASS_NAMES[label.numpy()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shuffle_buffer_size = 100 # affect randomness of dataset. it will take first 100 from dataset and shuffle and pick one.\n",
    "train_ds = (labeled_ds\n",
    "            .cache(\"./fibro_train.tfcache\")\n",
    "            .shuffle(buffer_size=shuffle_buffer_size)\n",
    "            .repeat()\n",
    "            .map(augment)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(buffer_size=AUTOTUNE) #time it takes to produce next element\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data_dir=r'C:\\Users\\kuki\\Desktop\\Skin\\TensorData\\test'\n",
    "test_data_dir = pathlib.Path(test_data_dir)\n",
    "test_image_count = len(list(test_data_dir.glob('*\\*.jpg')))\n",
    "test_list_ds = tf.data.Dataset.list_files(str(test_data_dir/'*/*'))\n",
    "test_labeled_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = (test_labeled_ds\n",
    "            .cache(\"./fibro_test.tfcache\")\n",
    "            .shuffle(buffer_size=shuffle_buffer_size)\n",
    "            .repeat()\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(buffer_size=AUTOTUNE) #time it takes to produce next element\n",
    "            )\n",
    "test_image_batch, test_label_batch = next(iter(test_ds))\n",
    "show_batch(test_image_batch.numpy(), test_label_batch.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# val_ds = (\n",
    "#     test_ds\n",
    "#     .map(convert, num_parallel_calls=AUTOTUNE)\n",
    "#     .batch(2*BATCH_SIZE)\n",
    "# )\n",
    "# val_image_count ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_aug = tf.keras.Sequential([\n",
    "  Flatten(input_shape=(100,100,3)),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(2)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_yesterday= Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cnn = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_new = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  #for multiple choice question"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=None, cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "# with mirrored_strategy.scope():\n",
    "#     model = tf.keras.Sequential([\n",
    "#     Flatten(input_shape=(100,100,3)),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(2)\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam',\n",
    "#               loss=loss_fn,\n",
    "#               metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model_aug\n",
    "model.compile(optimizer='adam',\n",
    "          loss=loss_fn,\n",
    "          metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "      steps_per_epoch=train_image_count // BATCH_SIZE,\n",
    "      epochs=epochs,\n",
    "      verbose=2,\n",
    "      validation_data=test_ds,\n",
    "      validation_steps=test_image_count // BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fn2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) #for A or B question\n",
    "\n",
    "model2 = model_yesterday\n",
    "model2.summary()\n",
    "model2.compile(optimizer='adam',\n",
    "          loss=loss_fn,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(train_ds, \n",
    "          steps_per_epoch=train_image_count // BATCH_SIZE,\n",
    "          epochs=epochs,\n",
    "          verbose=2,\n",
    "          validation_data=test_ds,\n",
    "          validation_steps=test_image_count // BATCH_SIZE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = history2.history['accuracy']\n",
    "val_acc = history2.history['val_accuracy']\n",
    "\n",
    "loss=history2.history['loss']\n",
    "val_loss=history2.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(image_batch)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}