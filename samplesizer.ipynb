{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_ds:  300 old\n",
      "list_ds:  300 old\n",
      "list_ds:  300 old\n",
      "list_ds:  300 old\n",
      "old : sample size = 1200\n",
      "list_ds:  400 young\n",
      "list_ds:  400 young\n",
      "list_ds:  400 young\n",
      "young : sample size = 2400\n",
      "test set size :  2400\n",
      "37/37 [==============================] - 3s 68ms/step - loss: 52.1010 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import average, maximum\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import pathlib\n",
    "\n",
    "def read_and_label(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    label = get_label(file_path)\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return tf.reshape(tf.where(parts[-4] == CLASS_NAMES), [])\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_hue(image, max_delta=0.05, seed=5)\n",
    "    image = tf.image.random_contrast(image, 0.95, 1.05, seed=5)  # tissue quality\n",
    "    image = tf.image.random_saturation(image, 0.95, 1.05, seed=5)  # stain quality\n",
    "    image = tf.image.random_brightness(image, max_delta=0.05)  # tissue thickness, glass transparency (clean)\n",
    "    image = tf.image.random_flip_left_right(image, seed=5)  # cell orientation\n",
    "    image = tf.image.random_flip_up_down(image, seed=5)  # cell orientation\n",
    "    image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))  # cell orientation\n",
    "    return image, label\n",
    "\n",
    "\n",
    "IMG_HEIGHT = 100\n",
    "IMG_WIDTH = 100\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "shuffle_buffer_size = 1000000\n",
    "\n",
    "test_data_dir = r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\test'\n",
    "test_data_dir = pathlib.Path(test_data_dir)\n",
    "CLASS_NAMES = np.array(\n",
    "    [item.name for item in test_data_dir.glob('*') if item.name != \"LICENSE.txt\" and item.name != \".DS_store\"])\n",
    "\n",
    "\n",
    "lr = 'e4'\n",
    "model_cnnA = tf.keras.models.load_model('cnn/Alex/'+lr+'/full_model.h5', compile=False)\n",
    "\n",
    "model_cnnA.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def load_dataset(dataset_dir):\n",
    "    dataset_dir = pathlib.Path(dataset_dir)\n",
    "    test_image_count2 = len(list(test_data_dir.glob('image\\*.jpg')))\n",
    "    list_ds = tf.data.Dataset.list_files(str(dataset_dir / 'image/*.jpg'))\n",
    "    # for f in list_ds.take(5):\n",
    "    #     print(f.numpy())\n",
    "    labeled_ds = list_ds.map(read_and_label, num_parallel_calls=AUTOTUNE)\n",
    "    return labeled_ds, test_image_count2\n",
    "\n",
    "\n",
    "def evalmodels(path):\n",
    "    datasett, datasettsize = load_dataset(path)\n",
    "    results = model_cnnA.evaluate(datasett.batch(1000))\n",
    "    print(os.path.basename(path), results[-1] * 100)\n",
    "\n",
    "\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\young\\sec001')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\young\\sec003')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\young\\sec007')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\young\\sec010')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\young\\sec016')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\young\\sec019')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "#\n",
    "#\n",
    "#\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\test\\young\\sec023')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\test\\young\\sec025')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\test\\young\\sec029')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "#\n",
    "#\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\old\\sec031')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\old\\sec037')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\old\\sec041')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\old\\sec045')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\old\\sec049')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\old\\sec062')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\old\\sec068')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\train\\old\\sec070')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "#\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\test\\old\\sec076')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\test\\old\\sec078')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\test\\old\\sec082')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "# evalmodels(r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\test\\old\\sec088')\n",
    "# print('---------------------------------------------------------------------------')\n",
    "#\n",
    "\n",
    "\n",
    "def balance(data_dir):\n",
    "    tmp = [0]\n",
    "    for CLASS, n in zip(CLASS_NAMES, samplesize):\n",
    "        secs = [_ for _ in data_dir.glob(CLASS+'/*')]\n",
    "        for idx,sec in enumerate(secs):\n",
    "            sec = os.path.join(sec,'image\\*.jpg')\n",
    "            list_ds = tf.data.Dataset.list_files(sec)\n",
    "            # subsample\n",
    "            list_ds = (list_ds\n",
    "                       .shuffle(shuffle_buffer_size)\n",
    "                       .take(n)\n",
    "                       )\n",
    "            labeled_ds = list_ds.map(read_and_label, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "            # add augment\n",
    "            sampleN = len(list(labeled_ds))\n",
    "            while sampleN < n:\n",
    "                labeled_ds_aug = (labeled_ds\n",
    "                                  .shuffle(shuffle_buffer_size)\n",
    "                                  .take(n-sampleN)\n",
    "                                  .map(augment,num_parallel_calls=AUTOTUNE)\n",
    "                                  )\n",
    "                labeled_ds = labeled_ds.concatenate(labeled_ds_aug)\n",
    "                sampleN = len(list(labeled_ds))\n",
    "            print('list_ds: ',len(list(labeled_ds)),CLASS)\n",
    "            # append\n",
    "            if tmp[0]==0:\n",
    "                tmp[idx]=labeled_ds\n",
    "            else:\n",
    "                labeled_ds = tmp[0].concatenate(labeled_ds)\n",
    "                tmp[0]=labeled_ds\n",
    "        print(CLASS,': sample size =',len(list(tmp[0])))\n",
    "    return tmp[0].shuffle(shuffle_buffer_size)\n",
    "\n",
    "test_data_dir = r'C:\\Users\\kuki\\Desktop\\Research\\Skin\\RCNN data\\test'\n",
    "test_data_dir = pathlib.Path(test_data_dir)\n",
    "samplesize=[300,400]\n",
    "test_labeled_ds = balance(test_data_dir)\n",
    "\n",
    "test_ds = (test_labeled_ds\n",
    "           .cache(\"./cache/fibro_test.tfcache\")\n",
    "           .shuffle(buffer_size=shuffle_buffer_size)\n",
    "           .repeat()\n",
    "           .batch(BATCH_SIZE)\n",
    "           .prefetch(buffer_size=AUTOTUNE)  # time it takes to produce next element\n",
    "           )\n",
    "test_image_count = len(list(test_labeled_ds))\n",
    "print('test set size : ', test_image_count)\n",
    "TEST_STEPS = test_image_count // BATCH_SIZE\n",
    "\n",
    "results = model_cnnA.evaluate(test_ds, steps=TEST_STEPS)\n",
    "\n",
    "probability_model = tf.keras.Sequential([model_cnnA,\n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(test_ds,steps=37)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0\n",
      " 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0]\n",
      "[0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1\n",
      " 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1]\n",
      "[1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0]\n",
      "[0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1\n",
      " 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0]\n",
      "[1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1\n",
      " 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0]\n",
      "[1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0]\n",
      "[0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0\n",
      " 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0]\n",
      "[1 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0]\n",
      "[1 1 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0\n",
      " 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1]\n",
      "[1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1\n",
      " 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0]\n",
      "[1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0]\n",
      "[0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      "[1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0\n",
      " 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 0]\n",
      "[1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 1 0]\n",
      "[0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0]\n",
      "[1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1\n",
      " 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0]\n",
      "[1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0]\n",
      "[1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1]\n",
      "[1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1\n",
      " 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1]\n",
      "[1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0]\n",
      "[1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1]\n",
      "[0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1]\n",
      "[1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 0 1\n",
      " 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1]\n",
      "[1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1\n",
      " 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1]\n",
      "[1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
      " 1 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1]\n",
      "[0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0]\n",
      "[1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1\n",
      " 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1]\n",
      "[0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1\n",
      " 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1]\n",
      "[1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1\n",
      " 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "[0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1]\n",
      "[0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0\n",
      " 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0\n",
      " 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1]\n",
      "[1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1]\n",
      "[0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 0\n",
      " 0 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0]\n",
      "[0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0\n",
      " 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 1]\n",
      "[0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0\n",
      " 1 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0]\n",
      "[1 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0\n",
      " 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0]\n",
      "[0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 0\n",
      " 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1]\n",
      "[1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0]\n",
      "[1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0\n",
      " 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 1 0]\n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0]\n",
      "[1 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0]\n",
      "[1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0\n",
      " 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1]\n",
      "[1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 0\n",
      " 1 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1]\n",
      "[0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0\n",
      " 0 1 1 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1]\n",
      "[0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0\n",
      " 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1]\n",
      "[1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 1]\n",
      "[1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1\n",
      " 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0]\n",
      "[0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0\n",
      " 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1]\n",
      "[0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 1\n",
      " 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1]\n",
      "[1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0]\n",
      "[0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 1 1\n",
      " 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 0]\n",
      "[0 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1\n",
      " 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0]\n",
      "[1 1 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1]\n",
      "[1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0]\n",
      "[0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0\n",
      " 0 0 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0]\n",
      "[1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0]\n",
      "[1 0 0 0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0\n",
      " 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0]\n",
      "[1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1\n",
      " 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0]\n",
      "[0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0]\n",
      "[1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1]\n",
      "[0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0\n",
      " 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 1]\n",
      "[1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1\n",
      " 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "[0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1]\n",
      "[0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1\n",
      " 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1]\n",
      "[1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1\n",
      " 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1]\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1\n",
      " 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0]\n",
      "[1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1\n",
      " 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 1 0 0]\n",
      "[1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0\n",
      " 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1]\n",
      "[0 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0]\n",
      "[1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0]\n",
      "[0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      " 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 0]\n",
      "[1 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1]\n",
      "[1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1]\n",
      "[1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1\n",
      " 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1]\n",
      "[0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0]\n",
      "[1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0]\n",
      "[0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0\n",
      " 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1]\n",
      "[0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1]\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0]\n",
      "[1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 0\n",
      " 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1]\n",
      "[1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0\n",
      " 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1]\n",
      "[1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0]\n",
      "[0 1 0 1 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0\n",
      " 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0]\n",
      "[1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1\n",
      " 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1]\n",
      "[1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0]\n",
      "[1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0\n",
      " 1 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1\n",
      " 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1]\n",
      "[1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1]\n",
      "[1 0 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 1]\n",
      "[1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1\n",
      " 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1]\n",
      "[0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1\n",
      " 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0]\n",
      "[1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 1]\n",
      "[1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0]\n",
      "[0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1\n",
      " 1 0 0 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0\n",
      " 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1]\n",
      "[1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "for img,label in test_ds.take(100).as_numpy_iterator():\n",
    "    print(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}